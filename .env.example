# ------------------------------
# Environment Variables for server & worker
# ------------------------------

# ------------------------------
# Server Configuration
# ------------------------------

# Log path
LOG_PATH=/tmp
# Graph designer server port
GRAPH_DESIGNER_SERVER_PORT=49483
# Server port
SERVER_PORT=8080
# Maximum number of workers
WORKERS_MAX=100
# Worker quit timeout in seconds
WORKER_QUIT_TIMEOUT_SECONDES=60

# Agora App ID and Agora App Certificate
# required: this variable must be set
AGORA_APP_ID=
AGORA_APP_CERTIFICATE=

# ------------------------------
# Worker Configuration
# ------------------------------

# Extension: bedrock_llm
# Extension: polly_tts
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_BEDROCK_MODEL=
AWS_REGION=

# Extension: agora_rtc
# Azure STT key and region
AZURE_STT_KEY=
AZURE_STT_REGION=

# Extension: azure_tts
# Azure TTS key and region
AZURE_TTS_KEY=
AZURE_TTS_REGION=

# Extension: cosy_tts
# Cosy TTS key
COSY_TTS_KEY=

# Extension: elevenlabs_tts
# ElevenLabs TTS key
ELEVENLABS_TTS_KEY=

# Extension: litellm
# Using Environment Variables, refer to https://docs.litellm.ai/docs/providers
# For example:
#     OpenAI
#         OPENAI_API_KEY=<your-api-key>
#         OPENAI_API_BASE=<openai-api-base>
#     AWS Bedrock
#         AWS_ACCESS_KEY_ID=<your-aws-access-key-id>
#         AWS_SECRET_ACCESS_KEY=<your-aws-secret-access-key>
#         AWS_REGION_NAME=<aws-region-name>
LITELLM_MODEL=gpt-4o-mini

# Extension: openai_chatgpt
# OpenAI API key
OPENAI_API_KEY=
# OpenAI base URL
# if using OpenAI, keep default. using other OpenAI-compatible providers, then set it to the other provider's address
OPENAI_BASE_URL=
# OpenAI Model
OPENAI_MODEL=gpt-4o-mini
# OpenAI proxy URL
OPENAI_PROXY_URL=

# Extension: qwen_llm
# Qwen API key
QWEN_API_KEY=
